{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6e4f4-6ca8-4a99-8459-6021ca6d27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0ad64-f163-4b0f-bc21-05a6eeada13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 48\n",
    "\n",
    "image_height = 299\n",
    "image_width = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3d060-9091-4f66-bbae-c744a6c58350",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_1 = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            rotation_range=5,\n",
    "                            width_shift_range=0.05,\n",
    "                            height_shift_range=0.05,\n",
    "                            shear_range=0.05,\n",
    "                            zoom_range=0.05,\n",
    "                            brightness_range = [0.95,1.05],\n",
    "                            horizontal_flip=False,\n",
    "                            vertical_flip=False,\n",
    "                            fill_mode='nearest'                                   \n",
    "                        )\n",
    "\n",
    "print('Data Augmentation 1 was created')\n",
    "\n",
    "data_generator_2 = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            rotation_range=10,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            brightness_range = [0.9,1.1],\n",
    "                            horizontal_flip=False,\n",
    "                            vertical_flip=False,\n",
    "                            fill_mode='nearest'                                   \n",
    "                        )\n",
    "print('Data Augmentation 2 was created')\n",
    "\n",
    "data_generator_3 = ImageDataGenerator (rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d3b8d-56ce-4201-9dce-b9663e71bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator1 = data_generator_1.flow_from_directory(\n",
    "    directory = r\"C:\\Users\\Rupam\\model\\chest_xray\\chest_xray\\train\", # images data path / folder in which images are there\n",
    "    color_mode = \"rgb\",\n",
    "    target_size = (image_height, image_width), # image height , image width\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = 42)\n",
    "\n",
    "print('Data Augmentation 1 was used to generate train data set\\n')\n",
    "\n",
    "# train_generator2 = data_generator_2.flow_from_directory(\n",
    "#     directory = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train\", # images data path / folder in which images are there\n",
    "#     color_mode = \"rgb\",\n",
    "#     target_size = (image_height, image_width), # image height , image width\n",
    "#     class_mode = \"categorical\",\n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     shuffle = True,\n",
    "#     seed = 42)\n",
    "\n",
    "# print('Data Augmentation 2 was used to generate train data set\\n')\n",
    "\n",
    "# train_generator3 = data_generator_3.flow_from_directory(\n",
    "#     directory = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train\", # images data path / folder in which images are there\n",
    "#     color_mode = \"rgb\",\n",
    "#     target_size = (image_height, image_width), # image height , image width\n",
    "#     class_mode = \"categorical\",\n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     shuffle = True,\n",
    "#     seed = 42)\n",
    "\n",
    "# print('Original images was used to generate train data set\\n')\n",
    "\n",
    "test_generator = data_generator_3.flow_from_directory(\n",
    "    directory = r\"C:\\Users\\Rupam\\model\\chest_xray\\chest_xray\\test\", # images data path / folder in which images are there\n",
    "    color_mode = \"rgb\",\n",
    "    target_size = (image_height, image_width), # image height , image width\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = 42)\n",
    "\n",
    "\n",
    "# val_generator = data_generator_3.flow_from_directory(\n",
    "#     directory = \"/kaggle/input/chest-xray-pneumonia/chest_xray/val\", # images data path / folder in which images are there\n",
    "#     color_mode = \"rgb\",\n",
    "#     target_size = (image_height, image_width), # image height , image width\n",
    "#     class_mode = \"categorical\",\n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     shuffle = True,\n",
    "#     seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6efc1-b091-4c49-802f-268e9dc8df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_class = train_generator1.class_indices\n",
    "print('Dictionary: {}'.format(dict_class))\n",
    "class_names = list(dict_class.keys())  # storing class/breed names in a list\n",
    "print('Class labels: {}'.format(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c092f3-cec4-4763-89ff-a2fa3209d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc8408-8e99-4e4c-a0a1-c891195e8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = np.unique(train_generator1.classes, return_counts=True)\n",
    "\n",
    "plt.title(\"Trainning dataset\", fontsize='16')\n",
    "plt.pie(frequency[1], labels = class_names, autopct='%1.0f%%');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa19d70-de87-4d74-bc9b-e0b5fda96037",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Characteristics of Train Data Set:\")\n",
    "print(\"Number of images:\", len(train_generator1.classes))\n",
    "print(\"Number of normal images:\", len([label for label in train_generator1.classes if label == 0]))\n",
    "print(\"Number of pneumonia images:\", len([label for label in train_generator1.classes if label == 1]))\n",
    "print()\n",
    "\n",
    "print(\"Dataset Characteristics of Test Data Set:\")\n",
    "print(\"Number of images:\", len(test_generator.classes))\n",
    "print(\"Number of normal images:\", len([label for label in test_generator.classes if label == 0]))\n",
    "print(\"Number of pneumonia images:\", len([label for label in test_generator.classes if label == 1]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4868d-433e-43a0-bbcd-496fd597900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d76374-3303-4edd-85d2-a3e749b7bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_generator1.classes), y= train_generator1.classes)\n",
    "class_weights = dict(zip(np.unique(train_generator1.classes), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e52073-c5c3-466c-9325-c64a38696631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train image data from Data Augmentation 1')\n",
    "img, label = next(train_generator1)\n",
    "# print(len(label))\n",
    "\n",
    "plt.figure(figsize=[10, 5])\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[np.argmax(label[i])])    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e1f62-d480-4f72-b74f-ea07e97cfe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7dd99-0fdc-4fba-9a5c-8e2044762a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "# Define the number of GPUs to use\n",
    "num_gpus = 2\n",
    "\n",
    "# Merge augmented image data for training\n",
    "# merged_train_generator = chain(train_generator1, train_generator2, train_generator3)\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Define the ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.001, patience=10, verbose=1)\n",
    "\n",
    "# For development purpose, we first limit the train data set to the original image data set\n",
    "# train_data = merged_train_generator\n",
    "# train_data = train_generator1\n",
    "train_data = train_generator1\n",
    "# train_data = test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b8fcf-07ae-43d8-a9a7-93efb205e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, MobileNetV2, DenseNet121\n",
    "\n",
    "# To chain two different data augmented images for training\n",
    "from itertools import chain\n",
    "\n",
    "#  Distributed Computing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c583dc-bcc8-4c4e-90c9-d9b71a9e8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eecac9-050c-42a2-bbda-fb8ab23bc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from keras import regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba191c-ff45-4b16-bd03-fb99f05243c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, MobileNetV2, DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf727f7-6ec4-41cc-a3be-deb589b72c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555659e3-ef9e-4e7d-a3d5-0e923cc5134f",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
